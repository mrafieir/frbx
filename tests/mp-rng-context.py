#!/usr/bin/env python3
import time
import numpy as np
from astropy.utils.misc import NumpyRNGContext
import multiprocessing as mp
import pathos.pools as pp


# This test ensures that all random number generators are independent in our catalog-making pipeline, which makes use
# of asynchronous mapping of queued jobs in parallel.

def level_0(n, seed):
    """
    This function takes a seed value and randomly samples from a uniform distribution of floats.

    E.g. simcat._rand_nfw().

    Args:

        n: (int) total number of random samples to be drawn.
        seed: (int or None) RNG seed.

    Returns:

        float, the last sample.
    """

    assert isinstance(n, int)
    assert isinstance(seed, int) or (seed is None)

    with NumpyRNGContext(seed):
        r = np.random.uniform(0, 1, n)

    return r[-1]


def level_1(n, seed):
    """
    This helper function sets a numpy RNG seed, draws a random float (uniform), and then calls level_0 with a None seed.
    It verifies whether the numpy seed is propagated in level_0.

    E.g. simcat.simulate().

    Args:

        n: (int) total number of random samples to be drawn in level_0.
        seed: (int) numpy RNG seed.

    Returns:

        two random floats, generated by numpy and level_0.
    """

    assert isinstance(n, int)
    assert isinstance(seed, int) and (seed is not None)

    np.random.seed(seed)
    t0 = np.random.ranf()

    t1 = level_0(n, seed=None)
    return t0, t1


def level_2(x):
    """
    This function demonstrates our high-level implementation of RNG seeds for generating random catalogs in parallel.

    E.g. gcat().

    Args:

        x: (list) with two elements,
           x[0] total number of random samples to be drawn in level_0 (only the last sample is returned though).
           x[1] catalog group index which is supposed to be a unique int per CPU core.

    Returns:

        level_1 function with appropriate input arguments.
    """

    assert isinstance(x[1], int)
    s = int(((1e7 * time.time()) % 1e4) + x[1])

    return level_1(x[0], seed=s)


n_group = 4
_n = 10

params = []
for index in range(n_group):
    params += [[_n, index]]

n_pro = min(n_group, mp.cpu_count())
pool = pp.ProcessPool(n_pro)

ret = pool.amap(level_2, params)
ret = np.unique(ret.get())

assert np.unique(ret).size == (2 * n_group)
print('mp-rng-context done.')
